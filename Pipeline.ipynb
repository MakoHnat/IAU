{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats as sm_stats\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "import vizualizacia_funkcie as visual\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn import impute \n",
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "from sklearn import base\n",
    "from sklearn import compose\n",
    "from sklearn import feature_selection\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./data/personal_train.csv\", index_col=0)\n",
    "df2 = pd.read_csv(\"./data/other_train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funckia, ktora mergne zaznamy, ktore su rovnake\n",
    "def piece_datarows_together(data):\n",
    "    \n",
    "    data = data.copy().set_index(\"name\")\n",
    "    \n",
    "    #toto nam vrati dataset, ktory obsahuje vsetky duplikaty, s ktorymi budeme pracovat\n",
    "    #proste to vrati data, ktore maju index, ktory je v datasete viac ako raz pouzity\n",
    "    duplicated = data[data.index.duplicated(keep=False)]\n",
    "    \n",
    "    index_values = duplicated.index.unique()\n",
    "    \n",
    "    #najprv vsetky hodnoty prenesieme do prveho vyskytu zaznamu daneho pacienta v datasete\n",
    "    for idx in index_values:\n",
    "        mini_dataset = duplicated.loc[idx] #toto vrati viacero zaznamov s rovnakych idx\n",
    "        \n",
    "        #zistim si, ktore atributy su nullove pre presne prvy zaznam a pre konkretne nullove atributy budem nadalej hladat\n",
    "        #nenullovu hodnotu v ostatnych zaznamoch s rovnakym idx\n",
    "        missing_mask = mini_dataset.iloc[0].isnull()\n",
    "        attributes = mini_dataset.columns.values\n",
    "        missing_attributes = attributes[missing_mask]\n",
    "        \n",
    "        #tu replacujem null hodnoty za nenullove\n",
    "        for attr in missing_attributes:\n",
    "            not_null = mini_dataset[attr][mini_dataset[attr].notnull()]\n",
    "            \n",
    "            if len(not_null) != 0:\n",
    "                mini_dataset.iloc[0][attr] = not_null.values[0]\n",
    "        \n",
    "        \n",
    "    #teraz uz mozme vymazat vsetky druhe, resp. ostatne zaznamy pacienta\n",
    "    duplicated_mask = data.index.duplicated(keep=\"first\")\n",
    "    \n",
    "    data = data.reset_index()\n",
    "    duplicated_indices = data.index.values[duplicated_mask]\n",
    "    \n",
    "    \n",
    "    return data.drop(index=duplicated_indices).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_proper_df(df1, df2, return_X_y=True):\n",
    "    data = df1.drop(columns=[\"address\"]).set_index(\"name\").join(df2.set_index(\"name\"), how=\"right\").reset_index()\n",
    "    data = piece_datarows_together(data)\n",
    "    \n",
    "    if return_X_y == True:\n",
    "        X = data.drop(columns=[\"class\"])\n",
    "        y = data[\"class\"]\n",
    "        return X,y\n",
    "    \n",
    "    else:\n",
    "        return data \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marital_status_categories(row):\n",
    "    \n",
    "    ms = row[\"marital-status\"]\n",
    "        \n",
    "    if ms is not np.nan and ms not in (\"Divorced\", \"Never-married\", \"Married-civ-spouse\"):\n",
    "        row[\"marital-status\"] = \"Other\"\n",
    "        \n",
    "    return row\n",
    "\n",
    "def relationship_categories(row):\n",
    "    \n",
    "    rel = row[\"relationship\"]\n",
    "        \n",
    "    if rel is not np.nan and rel not in (\"Not-in-family\", \"Husband\", \"Own-child\"):\n",
    "        row[\"relationship\"] = \"Other\"\n",
    "        \n",
    "    return row\n",
    "\n",
    "def occupation_categories(row):\n",
    "\n",
    "    occ = row[\"occupation\"]\n",
    "    \n",
    "    if occ is not np.nan and occ not in (\"Craft-repair\", \"Prof-specialty\", \"Exec-managerial\", \n",
    "                                         \"Adm-clerical\", \"Sales\", \"Other-service\", \"Machine-op-inspct\", \n",
    "                                         \"Transport-moving\"):\n",
    "        \n",
    "        row[\"occupation\"] = \"Other\"\n",
    "        \n",
    "    return row\n",
    "\n",
    "def workclass_categories(row):\n",
    "\n",
    "    wc = row[\"workclass\"]\n",
    "    \n",
    "    if wc is not np.nan and wc != \"Private\":\n",
    "        row[\"workclass\"] = \"Non-private\"\n",
    "        \n",
    "    return row\n",
    "\n",
    "def categorize_hours(row):\n",
    "    \n",
    "    hour = row[\"hours-per-week\"]\n",
    "    \n",
    "    if math.isnan(hour):\n",
    "        row[\"hours-per-week-cat\"] = math.nan\n",
    "    elif hour <= 35:\n",
    "        row[\"hours-per-week-cat\"] = \"<=35\"\n",
    "    elif hour <= 45:\n",
    "        row[\"hours-per-week-cat\"] = \"35< hours <=45\"\n",
    "    elif hour > 45:\n",
    "        row[\"hours-per-week-cat\"] = \">45\"        \n",
    "\n",
    "    return row\n",
    "\n",
    "def simplify_education(row):\n",
    "        \n",
    "    edu = row[\"education\"]\n",
    "        \n",
    "    if edu is np.nan:\n",
    "        row[\"simple-edu\"] = edu\n",
    "        \n",
    "    elif re.match(\"^([0-9][a-zA-Z])|(1[0-2][a-zA-Z])\", edu) or edu == \"Preschool\":\n",
    "        row[\"simple-edu\"] = \"Attending-school\"\n",
    "        \n",
    "    elif edu in [\"Assoc-acdm\", \"Assoc-voc\", \"Prof-school\"]:\n",
    "        row[\"simple-edu\"] = \"Edu after HS, no uni\"\n",
    "        \n",
    "    elif edu in [\"Masters\", \"Doctorate\"]:\n",
    "        row[\"simple-edu\"] = \"Masters/Doctorate\"\n",
    "        \n",
    "    else:\n",
    "        row[\"simple-edu\"] = row[\"education\"]\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_formatting(data):    \n",
    "    \n",
    "    data = data.copy()\n",
    "    \n",
    "    import re\n",
    "    dates = []\n",
    "\n",
    "    for index,row in data.iterrows():\n",
    "        dates.append(re.sub('\\d', '*',  row['date_of_birth']))\n",
    "\n",
    "    dates = list(set(dates))\n",
    "    dates\n",
    "\n",
    "    import re\n",
    "    from datetime import datetime\n",
    "\n",
    "    for index,row in data.iterrows():\n",
    "        line = row['date_of_birth']\n",
    "        if re.match(r\"^\\d{2}-\\d{2}-\\d{2}$\", line):\n",
    "            regex1 = line[0:2]\n",
    "            regex2 = line[3:5]\n",
    "            regex3 = line[6:8]\n",
    "\n",
    "            verbose = False\n",
    "            if (verbose == True):\n",
    "                if (int(regex1) > 31):\n",
    "                    print('Prvy udaj > 31: ',regex1)\n",
    "                if (int(regex2) > 31):\n",
    "                    print('Druhy udaj > 31: ',regex2)\n",
    "                if (int(regex3) > 31):\n",
    "                    print('Treti udaj > 31: ',regex3)\n",
    "\n",
    "    data['date_of_birth'] = data['date_of_birth'].map(lambda x: x[:10])\n",
    "\n",
    "    import re\n",
    "    from datetime import datetime\n",
    "\n",
    "    for index,row in data.iterrows():\n",
    "        line = row['date_of_birth']\n",
    "        dateObj = None\n",
    "        if re.match(r\"^\\d{2}-\", line):\n",
    "            newDate = '19' + line\n",
    "            dateObj = datetime.strptime(newDate,'%Y-%m-%d')\n",
    "        elif re.match(r\"^\\d{4}-\", line):\n",
    "            dateObj = datetime.strptime(line,'%Y-%m-%d')\n",
    "        elif re.match(r\"^\\d{4}/\", line):\n",
    "            dateObj = datetime.strptime(line,'%Y/%m/%d')\n",
    "        elif re.match(r\"^\\d{2}/\", line):\n",
    "            dateObj = datetime.strptime(line,'%d/%m/%Y')\n",
    "        data.at[index,'date_of_birth'] = dateObj.strftime('%d-%m-%Y')\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_useless_features(X):\n",
    "    \n",
    "    X = X.copy()\n",
    "    \n",
    "    useless_cols = [\"name\", \"race\", \"pregnant\", \"capital-loss\", \"capital-gain\", \"fnlwgt\", \"native-country\", \"address\"]\n",
    "    \n",
    "    return X.drop(columns=useless_cols)\n",
    "\n",
    "def add_oxygen_features(X):\n",
    "    X = X.copy()\n",
    "    X = X.apply(get_oxygen_stats, axis=1)\n",
    "    return X.drop(columns=[\"medical_info\"])\n",
    "    \n",
    "def get_oxygen_stats(row):\n",
    "    \n",
    "    string = row[\"medical_info\"]\n",
    "    \n",
    "    if string is np.nan:\n",
    "        return row\n",
    "    \n",
    "    string = string.replace(\"\\'\", \"\\\"\")\n",
    "    di = json.loads(string)\n",
    "    \n",
    "    for k in di.keys():\n",
    "        row[k] = float(di[k])\n",
    "        \n",
    "    return row\n",
    "\n",
    "def string_wrap_formatting(X):\n",
    "    X = X.copy()\n",
    "    return X.apply(string_formatting, axis=0)\n",
    "\n",
    "def string_formatting(col):\n",
    "    \n",
    "    if col.dtype == \"O\":\n",
    "        col = col.apply(lambda row: row.strip() if row is not np.nan else row)\n",
    "        col = col.apply(lambda row: np.nan if row is not np.nan and row == \"?\" else row)\n",
    "    \n",
    "    return col\n",
    "\n",
    "def bucket_cat_attr(X):\n",
    "   \n",
    "    X = X.copy()\n",
    "    \n",
    "    X = X.apply(marital_status_categories, axis=1)\n",
    "    X = X.apply(relationship_categories, axis=1)\n",
    "    X = X.apply(occupation_categories, axis=1)\n",
    "    X = X.apply(workclass_categories, axis=1)\n",
    "    \n",
    "    X[\"hours-per-week-cat\"] = 0\n",
    "    X = X.apply(categorize_hours, axis=1)\n",
    "    X = X.drop(columns=[\"hours-per-week\"])\n",
    "    \n",
    "    return X\n",
    "\n",
    "def repair_mean_glucose(X):\n",
    "    \n",
    "    X = X.copy()\n",
    "    X[\"mean_glucose\"] = pd.to_numeric(X['mean_glucose'], errors= 'coerce')\n",
    "    return X\n",
    "\n",
    "def prepare_age(X):\n",
    "    X = X.copy()\n",
    "    X = date_formatting(X)\n",
    "    \n",
    "    X = X.apply(make_bs_age_nan, axis=1)\n",
    "    X = X.apply(calculate_age, axis=1)\n",
    "    \n",
    "    X = X.drop(columns=[\"date_of_birth\"])\n",
    "    \n",
    "    return X\n",
    "    \n",
    "def make_bs_age_nan(row):\n",
    "    \n",
    "    age = row[\"age\"]\n",
    "    \n",
    "    if age is np.nan:\n",
    "        return row\n",
    "    \n",
    "    if age <= 0 or age >= 100:\n",
    "        row[\"age\"] = np.nan\n",
    "        \n",
    "    return row\n",
    "\n",
    "def calculate_age(row):\n",
    "    \n",
    "    if row[\"age\"] is np.nan or math.isnan(row[\"age\"]):\n",
    "    \n",
    "        born = row[\"date_of_birth\"]\n",
    "\n",
    "        born = datetime.strptime(born, \"%d-%m-%Y\").date()\n",
    "        today = date.today()\n",
    "        \n",
    "        row[\"age\"] = today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    " \n",
    "        \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prvy_pipeline = pipeline.Pipeline(steps=[\n",
    "    (\"feature_removal\", preprocessing.FunctionTransformer(remove_useless_features)),\n",
    "    (\"add_oxygen_attr\", preprocessing.FunctionTransformer(add_oxygen_features)),\n",
    "    (\"mean_glucose_to_num\", preprocessing.FunctionTransformer(repair_mean_glucose)),\n",
    "    (\"string_formatting\", preprocessing.FunctionTransformer(string_wrap_formatting)),\n",
    "    (\"bucket_cat_attr\", preprocessing.FunctionTransformer(bucket_cat_attr)),\n",
    "    (\"preprocess_age\", preprocessing.FunctionTransformer(prepare_age))\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tato funkcia je ekvivalentna s hociktorym inym transformatorom v scikit-learne, ci uz na imputaciu, transformaciu, scaling a ine veci\n",
    "#jediny rozdiel je, ze to nevrati numpy array, ale DataFrame, a vdaka tomu si uchvoavam nazvy stlpcov\n",
    "class KeepDataFrame(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self, transformation):\n",
    "        self.transformation = transformation\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        if self.transformation is not None:\n",
    "            self.transformation.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        if self.transformation is not None:\n",
    "        \n",
    "            X = X.copy()\n",
    "            cols = X.columns\n",
    "            indices = X.index\n",
    "\n",
    "            X = self.transformation.transform(X)\n",
    "\n",
    "            X = pd.DataFrame(X, columns=cols, index=indices)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCatImputing(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self, imputer_type=\"knn\"):\n",
    "        self.ordinal_encoder = None\n",
    "        self.imputer = None\n",
    "        self.imputer_type = imputer_type\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        print(\"FIT\")\n",
    "        \n",
    "        X = X.copy()\n",
    "        \n",
    "        columns = X.columns.values\n",
    "        indices = X.index\n",
    "\n",
    "        null_values = pd.DataFrame(index=pd.Index([-1]), columns=columns, data=[[np.nan for i in range(len(columns))]])\n",
    "        X = pd.concat([null_values,X])\n",
    "\n",
    "        self.ordinal_encoder = ce.ordinal.OrdinalEncoder(handle_missing=\"return_nan\", handle_unknown=\"return_nan\")\n",
    "        X = self.ordinal_encoder.fit_transform(X)\n",
    "        \n",
    "        X = X[1:]\n",
    "        \n",
    "        if self.imputer_type == \"knn\":\n",
    "            self.imputer = impute.KNNImputer()\n",
    "            X = self.imputer.fit(X)\n",
    "        \n",
    "        elif self.imputer_type == \"iterative\":\n",
    "\n",
    "            self.imputer = impute.IterativeImputer(max_iter=20, random_state=42, initial_strategy=\"most_frequent\", \n",
    "                                                  min_value=X.min(), max_value=X.max())\n",
    "\n",
    "\n",
    "            try:\n",
    "                X = self.imputer.fit(X)\n",
    "            except (ValueError, np.linalg.LinAlgError):\n",
    "                print(\"Jeden error bol trapnuty, kedy funkcii vadili NaNs. Tento error je ale divny, lebo mu to vadi\", \\\n",
    "                  \"len prvy krat, a potom to uz ide...\")\n",
    "                X = self.imputer.fit(X)\n",
    "            \n",
    "        return self\n",
    "               \n",
    "\n",
    "    def transform(self, X):\n",
    "        print(\"TRANSFORM\")\n",
    "        \n",
    "        X = X.copy()\n",
    "        \n",
    "        indices = X.index\n",
    "        columns = X.columns\n",
    "    \n",
    "        X = self.ordinal_encoder.transform(X)\n",
    "        X = self.imputer.transform(X).round()\n",
    "        \n",
    "        X = pd.DataFrame(data=X, columns=columns, index=indices)\n",
    "        \n",
    "        X = self.ordinal_encoder.inverse_transform(X)\n",
    "        \n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapColumnTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self, column_transformer, keep_original_cols=True):\n",
    "        self.column_transformer = column_transformer\n",
    "        self.keep_original_cols = keep_original_cols\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.column_transformer.fit(X)\n",
    "        return self\n",
    "        \n",
    "            \n",
    "    def transform(self, X):\n",
    "        indices = X.index\n",
    "        \n",
    "        columns = []\n",
    "        \n",
    "        for transf in self.column_transformer.transformers:\n",
    "            columns += transf[2]\n",
    "           \n",
    "\n",
    "        X = X.copy()\n",
    "        \n",
    "        X = self.column_transformer.transform(X)\n",
    "\n",
    "        if self.keep_original_cols == True:\n",
    "            X = pd.DataFrame(X, columns=columns, index=indices)\n",
    "        \n",
    "        else:\n",
    "            X = pd.DataFrame(X, index=indices)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxygen_attr = [\"mean_oxygen\", \"std_oxygen\", \"kurtosis_oxygen\", \"skewness_oxygen\"]\n",
    "glucose_attr = [\"mean_glucose\", \"std_glucose\", \"kurtosis_glucose\", \"skewness_glucose\"]\n",
    "\n",
    "vztahy_attr = [\"relationship\", \"marital-status\"]\n",
    "work_attr = [\"workclass\", \"occupation\", \"hours-per-week-cat\", \"income\"]\n",
    "edu_attr = [\"education\", \"education-num\"]\n",
    "\n",
    "impute_col_transf = compose.ColumnTransformer(transformers=[\n",
    "    (\"oxygen_n_glucose_impute\", KeepDataFrame(impute.IterativeImputer(max_iter=50)), oxygen_attr + glucose_attr),\n",
    "    (\"vztahy_impute\", CustomCatImputing(imputer_type=\"knn\"), vztahy_attr),\n",
    "    (\"work_impute\", CustomCatImputing(imputer_type=\"knn\"), work_attr),\n",
    "    (\"edu_impute\", CustomCatImputing(imputer_type=\"knn\"), edu_attr),\n",
    "    (\"sex_impute\", KeepDataFrame(impute.SimpleImputer(strategy=\"most_frequent\")), [\"sex\"]),\n",
    "    (\"age_impute\", KeepDataFrame(impute.SimpleImputer()), [\"age\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NonLinearTransf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_outliers(a):\n",
    "    q25 = a.quantile(0.25)\n",
    "    q75 = a.quantile(0.75)\n",
    "    \n",
    "    iqr = q75-q25\n",
    "        \n",
    "    lower = q25 - 1.5 * iqr\n",
    "    upper = q75 + 1.5 * iqr\n",
    "    \n",
    "    return a[(a > upper) | (a < lower)]\n",
    "\n",
    "def removing_outliers_per_class(data, column, clz=\"class\"):\n",
    "\n",
    "    data = data.copy()\n",
    "    \n",
    "    data_y0 = data[data[clz] == 0][column]\n",
    "    data_y1 = data[data[clz] == 1][column]\n",
    "        \n",
    "    idx = identify_outliers(data_y0).index.values\n",
    "    data = data.drop(index=idx)\n",
    "\n",
    "    idx = identify_outliers(data_y1).index.values\n",
    "    data = data.drop(index=idx)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_transf_attr = [\"mean_oxygen\", \"skewness_oxygen\", \"kurtosis_oxygen\", \"skewness_glucose\"]\n",
    "quant_transf_attr = [\"age\"]\n",
    "other_attr = [\"std_oxygen\", \"mean_glucose\", \"std_glucose\", \"kurtosis_glucose\", \"sex\", \"education\"] + vztahy_attr + work_attr\n",
    "\n",
    "non_linear_transf =  compose.ColumnTransformer(transformers=[\n",
    "   (\"power_transformer\", KeepDataFrame(preprocessing.PowerTransformer()), power_transf_attr),\n",
    "   (\"quantile_transformer\", KeepDataFrame(preprocessing.QuantileTransformer(output_distribution=\"normal\")), quant_transf_attr),\n",
    "   (\"pass\", \"passthrough\", other_attr)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Outliers - resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierRemoval(base.BaseEstimator):\n",
    "     \n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit_resample(self, X, y):\n",
    "        print(\"fit_resample\")\n",
    "        return self.resample(X, y)\n",
    "                \n",
    "    def resample(self, X, y):\n",
    "        print(\"resample\")\n",
    "        \n",
    "        X = X.copy()\n",
    "        y = y.copy()\n",
    "        \n",
    "        data = X.join(y, how=\"left\")\n",
    "        clz = \"class\"\n",
    "        \n",
    "        \n",
    "        for c in self.columns:\n",
    "            \n",
    "            data_y0 = data[data[clz] == 0][c]\n",
    "            data_y1 = data[data[clz] == 1][c]\n",
    "\n",
    "            idx = identify_outliers(data_y0).index.values\n",
    "            data = data.drop(index=idx)\n",
    "\n",
    "            idx = identify_outliers(data_y1).index.values\n",
    "            data = data.drop(index=idx)\n",
    "            \n",
    "        #toto je specialne pre target atribut\n",
    "        if data[clz].isnull().sum() > 0:\n",
    "            idx = data[data[clz].isnull()].index.values\n",
    "            data = data.drop(index=idx)\n",
    "\n",
    "            \n",
    "        X = data.drop(columns=[\"class\"])\n",
    "        y = data[\"class\"]\n",
    "            \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_columns = oxygen_attr + glucose_attr + [\"age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling a Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = pipeline.Pipeline(steps=[\n",
    "    (\"standard_scaler\", preprocessing.StandardScaler())\n",
    "])\n",
    "\n",
    "onehot = pipeline.Pipeline(steps=[\n",
    "    (\"one_hot_enc\", preprocessing.OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "ord_mapping = [\n",
    "    {\"col\": \"education\", \"mapping\": {\n",
    "        \"Attending-school\": 1, \n",
    "        \"HS-grad\": 2,\n",
    "        \"Edu after HS, no uni\": 3,\n",
    "        \"Some-college\": 4,\n",
    "        \"Bachelors\": 5,\n",
    "        \"Masters/Doctorate\": 6}},\n",
    "    \n",
    "    {\"col\": \"hours-per-week-cat\", \"mapping\": {\n",
    "        \"<=35\": 1,\n",
    "        \"35< hours <=45\": 2,\n",
    "        \">45\": 3}},\n",
    "    \n",
    "    {\"col\": \"income\", \"mapping\": {\n",
    "        \"<=50K\": 1,\n",
    "        \">50K\": 2}}\n",
    "]\n",
    "\n",
    "\n",
    "ordinal = pipeline.Pipeline(steps=[\n",
    "    (\"ordinal_enc\", ce.OrdinalEncoder(mapping=ord_mapping, handle_unknown=\"return_nan\")),\n",
    "    (\"impute_unknown\", impute.SimpleImputer(strategy=\"most_frequent\"))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_attr = [\"age\"] + oxygen_attr + glucose_attr\n",
    "\n",
    "onehot_attr = [\"sex\", \"marital-status\", \"relationship\", \"occupation\", \"workclass\"]\n",
    "\n",
    "ordinal_attr = [\"education\", \"hours-per-week-cat\", \"income\"]\n",
    "\n",
    "last_col_transf = compose.ColumnTransformer(transformers=[\n",
    "    (\"num_attr_scaling\", scaling, scaling_attr),\n",
    "    (\"cat_attr_onehot_enc\", onehot, onehot_attr),\n",
    "    (\"cat_attr_ordinal_enc\", ordinal, ordinal_attr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tato trieda sa hra na klasifikator, aby mohla byt poslednym krokom v pipeline\n",
    "#sluzi na to, aby sme vedeli z pipelinu dostat nove X a y, ktore uz mozme rovno hodit do nejakeho modelu\n",
    "class Return_X_y(base.BaseEstimator, base.ClassifierMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def fit_predict(self, X, y=None):\n",
    "        self.fit(X,y)\n",
    "        return self.predict(X,y)\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        if y is None:\n",
    "            return X\n",
    "        \n",
    "        y = y.values\n",
    "        return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PIPELINE = imblearn.pipeline.Pipeline(steps=[\n",
    "    (\"feature_removal\", preprocessing.FunctionTransformer(remove_useless_features)),\n",
    "    (\"add_oxygen_attr\", preprocessing.FunctionTransformer(add_oxygen_features)),\n",
    "    (\"mean_glucose_to_num\", preprocessing.FunctionTransformer(repair_mean_glucose)),\n",
    "    (\"string_formatting\", preprocessing.FunctionTransformer(string_wrap_formatting)),\n",
    "    (\"bucket_cat_attr\", preprocessing.FunctionTransformer(bucket_cat_attr)),\n",
    "    (\"imputation_stage\",  WrapColumnTransformer(impute_col_transf)),\n",
    "    (\"non_linear_transform\", WrapColumnTransformer(non_linear_transf)),\n",
    "    (\"outlier_removal\", OutlierRemoval(outlier_columns)),\n",
    "    (\"scaling_n_encoding_stage\", WrapColumnTransformer(last_col_transf, keep_original_cols=False)),\n",
    "    (\"var_thresh\", feature_selection.VarianceThreshold(threshold=(0.9*(1-0.9)))),\n",
    "    (\"return_X_y\", Return_X_y())\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-7f4a873f9dd0>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mini_dataset.iloc[0][attr] = not_null.values[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIT\n",
      "TRANSFORM\n",
      "FIT\n",
      "TRANSFORM\n",
      "FIT\n",
      "TRANSFORM\n",
      "TRANSFORM\n",
      "TRANSFORM\n",
      "TRANSFORM\n",
      "fit_resample\n",
      "resample\n"
     ]
    }
   ],
   "source": [
    "X,y = one_proper_df(df1, df2, return_X_y=True)\n",
    "\n",
    "new_data = MAIN_PIPELINE.fit_predict(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 29)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ulozenie datasetu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 1., 1.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.311276</td>\n",
       "      <td>-0.977285</td>\n",
       "      <td>-0.686528</td>\n",
       "      <td>0.764774</td>\n",
       "      <td>0.725310</td>\n",
       "      <td>0.602871</td>\n",
       "      <td>-0.382023</td>\n",
       "      <td>-0.587876</td>\n",
       "      <td>-0.348529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.202668</td>\n",
       "      <td>-1.180374</td>\n",
       "      <td>-0.668629</td>\n",
       "      <td>1.159486</td>\n",
       "      <td>1.018022</td>\n",
       "      <td>0.577096</td>\n",
       "      <td>1.298356</td>\n",
       "      <td>-0.538880</td>\n",
       "      <td>-1.335921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.809311</td>\n",
       "      <td>-1.093507</td>\n",
       "      <td>-0.900445</td>\n",
       "      <td>1.530003</td>\n",
       "      <td>1.723676</td>\n",
       "      <td>0.163982</td>\n",
       "      <td>-1.211630</td>\n",
       "      <td>-0.571226</td>\n",
       "      <td>0.591841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.967692</td>\n",
       "      <td>-1.344030</td>\n",
       "      <td>-0.862443</td>\n",
       "      <td>1.602909</td>\n",
       "      <td>1.593859</td>\n",
       "      <td>1.044280</td>\n",
       "      <td>1.392975</td>\n",
       "      <td>-0.673214</td>\n",
       "      <td>-0.848126</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.439565</td>\n",
       "      <td>-0.153038</td>\n",
       "      <td>-0.176263</td>\n",
       "      <td>0.128825</td>\n",
       "      <td>0.032148</td>\n",
       "      <td>0.611151</td>\n",
       "      <td>1.094501</td>\n",
       "      <td>-0.523667</td>\n",
       "      <td>-0.842197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>-1.501722</td>\n",
       "      <td>-0.726906</td>\n",
       "      <td>-0.738099</td>\n",
       "      <td>0.691472</td>\n",
       "      <td>0.810619</td>\n",
       "      <td>0.701140</td>\n",
       "      <td>0.750425</td>\n",
       "      <td>-0.632541</td>\n",
       "      <td>-0.594752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>-0.025291</td>\n",
       "      <td>-0.242444</td>\n",
       "      <td>-0.509509</td>\n",
       "      <td>0.249518</td>\n",
       "      <td>0.274989</td>\n",
       "      <td>-0.022706</td>\n",
       "      <td>-1.226564</td>\n",
       "      <td>-0.341722</td>\n",
       "      <td>0.547458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>-0.515114</td>\n",
       "      <td>-0.992622</td>\n",
       "      <td>-0.720888</td>\n",
       "      <td>1.083943</td>\n",
       "      <td>1.056290</td>\n",
       "      <td>0.902260</td>\n",
       "      <td>-0.184959</td>\n",
       "      <td>-0.528989</td>\n",
       "      <td>-0.655931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>0.960542</td>\n",
       "      <td>1.784448</td>\n",
       "      <td>2.805246</td>\n",
       "      <td>-1.714086</td>\n",
       "      <td>-1.918628</td>\n",
       "      <td>-1.487120</td>\n",
       "      <td>-1.474046</td>\n",
       "      <td>1.729647</td>\n",
       "      <td>1.649441</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>-0.670213</td>\n",
       "      <td>1.547616</td>\n",
       "      <td>2.248448</td>\n",
       "      <td>-1.366805</td>\n",
       "      <td>-1.465959</td>\n",
       "      <td>-0.556886</td>\n",
       "      <td>1.058741</td>\n",
       "      <td>0.264505</td>\n",
       "      <td>0.594517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.311276 -0.977285 -0.686528  0.764774  0.725310  0.602871 -0.382023   \n",
       "1    -0.202668 -1.180374 -0.668629  1.159486  1.018022  0.577096  1.298356   \n",
       "2    -0.809311 -1.093507 -0.900445  1.530003  1.723676  0.163982 -1.211630   \n",
       "3    -1.967692 -1.344030 -0.862443  1.602909  1.593859  1.044280  1.392975   \n",
       "4    -0.439565 -0.153038 -0.176263  0.128825  0.032148  0.611151  1.094501   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3258 -1.501722 -0.726906 -0.738099  0.691472  0.810619  0.701140  0.750425   \n",
       "3259 -0.025291 -0.242444 -0.509509  0.249518  0.274989 -0.022706 -1.226564   \n",
       "3260 -0.515114 -0.992622 -0.720888  1.083943  1.056290  0.902260 -0.184959   \n",
       "3261  0.960542  1.784448  2.805246 -1.714086 -1.918628 -1.487120 -1.474046   \n",
       "3262 -0.670213  1.547616  2.248448 -1.366805 -1.465959 -0.556886  1.058741   \n",
       "\n",
       "             7         8    9  ...   20   21   22   23   24   25   26   27  \\\n",
       "0    -0.587876 -0.348529  1.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  2.0  2.0   \n",
       "1    -0.538880 -1.335921  0.0  ...  0.0  0.0  0.0  1.0  1.0  0.0  4.0  2.0   \n",
       "2    -0.571226  0.591841  1.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  2.0  2.0   \n",
       "3    -0.673214 -0.848126  1.0  ...  0.0  0.0  0.0  1.0  0.0  1.0  2.0  2.0   \n",
       "4    -0.523667 -0.842197  0.0  ...  0.0  0.0  1.0  0.0  0.0  1.0  2.0  3.0   \n",
       "...        ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "3258 -0.632541 -0.594752  0.0  ...  0.0  0.0  0.0  1.0  0.0  1.0  2.0  2.0   \n",
       "3259 -0.341722  0.547458  0.0  ...  0.0  1.0  0.0  0.0  0.0  1.0  5.0  2.0   \n",
       "3260 -0.528989 -0.655931  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  5.0  3.0   \n",
       "3261  1.729647  1.649441  1.0  ...  0.0  0.0  0.0  1.0  0.0  1.0  2.0  2.0   \n",
       "3262  0.264505  0.594517  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  2.0  2.0   \n",
       "\n",
       "       28  class  \n",
       "0     1.0    0.0  \n",
       "1     1.0    0.0  \n",
       "2     1.0    0.0  \n",
       "3     1.0    0.0  \n",
       "4     2.0    0.0  \n",
       "...   ...    ...  \n",
       "3258  1.0    0.0  \n",
       "3259  2.0    0.0  \n",
       "3260  2.0    0.0  \n",
       "3261  1.0    1.0  \n",
       "3262  1.0    1.0  \n",
       "\n",
       "[3263 rows x 30 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(new_data[0])\n",
    "y = pd.Series(new_data[1])\n",
    "\n",
    "data[\"class\"] = y\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"./preprocessed_data/train.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
