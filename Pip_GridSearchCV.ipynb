{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats as sm_stats\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "import vizualizacia_funkcie as visual\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "from sklearn import base\n",
    "from sklearn import compose\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "import imblearn\n",
    "import preprocessing_pipeline as prep_pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dlzka personal_train 3933\n",
      "Pocet unique pacientov 3933\n",
      "Rozdiel medzi velkostou df a poctu pacientov 0\n",
      "\n",
      "Dlzka other_train 3983\n",
      "Pocet unique pacientov 3933\n",
      "Rozdiel medzi velkostou df a poctu pacientov 50\n",
      "\n",
      "Dlzka noveho dataframu 3933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcel\\OneDrive\\Dokumenty\\FIIT\\5.semester\\IAU_prj\\preprocessing_pipeline.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mini_dataset.iloc[0][attr] = not_null.values[0]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"./data/personal_train.csv\", index_col=0)\n",
    "df2 = pd.read_csv(\"./data/other_train.csv\", index_col=0)\n",
    "\n",
    "print(\"Dlzka personal_train\", df1.shape[0])\n",
    "print(\"Pocet unique pacientov\", df1[\"name\"].nunique())\n",
    "print(\"Rozdiel medzi velkostou df a poctu pacientov\", df1.shape[0] - df1[\"name\"].nunique())\n",
    "print()\n",
    "\n",
    "print(\"Dlzka other_train\", df2.shape[0])\n",
    "print(\"Pocet unique pacientov\", df2[\"name\"].nunique())\n",
    "print(\"Rozdiel medzi velkostou df a poctu pacientov\", df2.shape[0] - df2[\"name\"].nunique())\n",
    "print()\n",
    "\n",
    "X1,y1 = prep_pip.one_proper_df(df1, df2)\n",
    "print(\"Dlzka noveho dataframu\", X1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dlzka personal_valid 1311\n",
      "Pocet unique pacientov 1311\n",
      "Rozdiel medzi velkostou df a poctu pacientov 0\n",
      "\n",
      "Dlzka other_valid 1361\n",
      "Pocet unique pacientov 1311\n",
      "Rozdiel medzi velkostou df a poctu pacientov 50\n",
      "\n",
      "Dlzka noveho dataframu 1311\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"./data/personal_valid.csv\", index_col=0)\n",
    "df2 = pd.read_csv(\"./data/other_valid.csv\", index_col=0)\n",
    "\n",
    "print(\"Dlzka personal_valid\", df1.shape[0])\n",
    "print(\"Pocet unique pacientov\", df1[\"name\"].nunique())\n",
    "print(\"Rozdiel medzi velkostou df a poctu pacientov\", df1.shape[0] - df1[\"name\"].nunique())\n",
    "print()\n",
    "\n",
    "print(\"Dlzka other_valid\", df2.shape[0])\n",
    "print(\"Pocet unique pacientov\", df2[\"name\"].nunique())\n",
    "print(\"Rozdiel medzi velkostou df a poctu pacientov\", df2.shape[0] - df2[\"name\"].nunique())\n",
    "print()\n",
    "\n",
    "X2,y2 = prep_pip.one_proper_df(df1, df2)\n",
    "print(\"Dlzka noveho dataframu\", X2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1[\"class\"] = y1\n",
    "X2[\"class\"] = y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5244, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([X1,X2])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je potrebne vymazat z datasetu vsetky data, kde target attribute - class je NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5227, 25)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reset_index(drop=True)\n",
    "indices = data.loc[data[\"class\"].isnull()].index.values\n",
    "\n",
    "data = data.drop(index=indices)\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toto je tam len kvoli tomu, aby sme vobec vedeli deklarovat dany pipeline - Teda je potrebne tam dat nejaky krok, ktory hned vymazeme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu sa pridaju kroky z preprocessingu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_steps = prep_pip.get_preprocessing_steps()\n",
    "\n",
    "pip = imblearn.pipeline.Pipeline(steps=[\n",
    "    step for step in prep_steps\n",
    "])\n",
    "    \n",
    "from sklearn import tree\n",
    "pip.steps.append(\n",
    "    (\"classifier\", tree.DecisionTreeClassifier())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu sa specialne volaju parametre, kedze sa nachadzaju v pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"classifier__criterion\" : [\"gini\", \"entropy\"],\n",
    "    \"classifier__max_depth\" :  [3,5,10]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ked sa pouzije n_jobs=-1, co by malo byt tolko procesov paralelne ako pocet threadov, tak to dava NaN vysledky :(\n",
    "\n",
    "Takze budeme musiet to mat pomale..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = model_selection.GridSearchCV(pip, param_grid, scoring=\"accuracy\", cv=10, verbose=1, refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('feature_removal',\n",
       "                                        FunctionTransformer(func=<function remove_useless_features at 0x000001EF961CD1F0>)),\n",
       "                                       ('add_oxygen_attr',\n",
       "                                        FunctionTransformer(func=<function add_oxygen_features at 0x000001EF961CD280>)),\n",
       "                                       ('mean_glucose_to_num',\n",
       "                                        FunctionTransformer(func=<function repair_mean_glucose at 0x000001EF961CD550>)),\n",
       "                                       ('string_...\n",
       "                                                                                 'occupation_1',\n",
       "                                                                                 'occupation_2',\n",
       "                                                                                 'occupation_3',\n",
       "                                                                                 'occupation_4',\n",
       "                                                                                 'occupation_5',\n",
       "                                                                                 'occupation_6',\n",
       "                                                                                 'occupation_7',\n",
       "                                                                                 'occupation_8',\n",
       "                                                                                 'workclass_0',\n",
       "                                                                                 'workclass_1', ...],\n",
       "                                                              keep_original_cols=False)),\n",
       "                                       ('classifier',\n",
       "                                        DecisionTreeClassifier())]),\n",
       "             param_grid={'classifier__criterion': ['gini', 'entropy'],\n",
       "                         'classifier__max_depth': [3, 5, 10]},\n",
       "             refit=False, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns=[\"class\"])\n",
    "y = data[\"class\"]\n",
    "\n",
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu su vysledky..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.91839316, 2.56954417, 2.58535528, 2.7628459 , 2.74674795,\n",
       "        2.37328324]),\n",
       " 'std_fit_time': array([0.16967288, 0.13973361, 0.12681291, 0.13668663, 0.18467865,\n",
       "        0.22084841]),\n",
       " 'mean_score_time': array([0.34487875, 0.27607479, 0.28568659, 0.30517044, 0.30639613,\n",
       "        0.27481587]),\n",
       " 'std_score_time': array([0.05809854, 0.03113603, 0.0280337 , 0.02876131, 0.02755588,\n",
       "        0.02557769]),\n",
       " 'param_classifier__criterion': masked_array(data=['gini', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy'],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__max_depth': masked_array(data=[3, 5, 10, 3, 5, 10],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__criterion': 'gini', 'classifier__max_depth': 3},\n",
       "  {'classifier__criterion': 'gini', 'classifier__max_depth': 5},\n",
       "  {'classifier__criterion': 'gini', 'classifier__max_depth': 10},\n",
       "  {'classifier__criterion': 'entropy', 'classifier__max_depth': 3},\n",
       "  {'classifier__criterion': 'entropy', 'classifier__max_depth': 5},\n",
       "  {'classifier__criterion': 'entropy', 'classifier__max_depth': 10}],\n",
       " 'split0_test_score': array([0.87189293, 0.87189293, 0.86998088, 0.87189293, 0.87189293,\n",
       "        0.86998088]),\n",
       " 'split1_test_score': array([0.89292543, 0.89292543, 0.88910134, 0.89292543, 0.89292543,\n",
       "        0.88910134]),\n",
       " 'split2_test_score': array([0.8833652 , 0.8833652 , 0.87954111, 0.8833652 , 0.8833652 ,\n",
       "        0.88718929]),\n",
       " 'split3_test_score': array([0.89292543, 0.90439771, 0.88527725, 0.89292543, 0.90248566,\n",
       "        0.89101338]),\n",
       " 'split4_test_score': array([0.91204589, 0.91778203, 0.91778203, 0.91395793, 0.91395793,\n",
       "        0.9082218 ]),\n",
       " 'split5_test_score': array([0.88527725, 0.88718929, 0.88718929, 0.88527725, 0.88527725,\n",
       "        0.88527725]),\n",
       " 'split6_test_score': array([0.89483748, 0.89674952, 0.89292543, 0.89483748, 0.89483748,\n",
       "        0.89483748]),\n",
       " 'split7_test_score': array([0.88505747, 0.88314176, 0.87739464, 0.88505747, 0.88505747,\n",
       "        0.88314176]),\n",
       " 'split8_test_score': array([0.87356322, 0.87356322, 0.87164751, 0.87356322, 0.87356322,\n",
       "        0.86590038]),\n",
       " 'split9_test_score': array([0.88888889, 0.8908046 , 0.88888889, 0.88888889, 0.88888889,\n",
       "        0.88888889]),\n",
       " 'mean_test_score': array([0.88807792, 0.89018117, 0.88597284, 0.88826912, 0.88922515,\n",
       "        0.88635524]),\n",
       " 'std_test_score': array([0.01086102, 0.01315507, 0.01286984, 0.01128965, 0.01202436,\n",
       "        0.01133339]),\n",
       " 'rank_test_score': array([4, 1, 6, 3, 2, 5])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8901811681794539"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__criterion': 'gini', 'classifier__max_depth': 5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
