{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats as sm_stats\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "import vizualizacia_funkcie as visual\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "from sklearn import base\n",
    "from sklearn import compose\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "import imblearn\n",
    "import preprocessing_pipeline as prep_pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dlzka personal_train 3933\n",
      "Pocet unique pacientov 3933\n",
      "Rozdiel medzi velkostou df a poctu pacientov 0\n",
      "\n",
      "Dlzka other_train 3983\n",
      "Pocet unique pacientov 3933\n",
      "Rozdiel medzi velkostou df a poctu pacientov 50\n",
      "\n",
      "Dlzka noveho dataframu 3933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcel\\OneDrive\\Dokumenty\\FIIT\\5.semester\\IAU_prj\\preprocessing_pipeline.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mini_dataset.iloc[0][attr] = not_null.values[0]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"./data/personal_train.csv\", index_col=0)\n",
    "df2 = pd.read_csv(\"./data/other_train.csv\", index_col=0)\n",
    "\n",
    "print(\"Dlzka personal_train\", df1.shape[0])\n",
    "print(\"Pocet unique pacientov\", df1[\"name\"].nunique())\n",
    "print(\"Rozdiel medzi velkostou df a poctu pacientov\", df1.shape[0] - df1[\"name\"].nunique())\n",
    "print()\n",
    "\n",
    "print(\"Dlzka other_train\", df2.shape[0])\n",
    "print(\"Pocet unique pacientov\", df2[\"name\"].nunique())\n",
    "print(\"Rozdiel medzi velkostou df a poctu pacientov\", df2.shape[0] - df2[\"name\"].nunique())\n",
    "print()\n",
    "\n",
    "X1,y1 = prep_pip.one_proper_df(df1, df2)\n",
    "print(\"Dlzka noveho dataframu\", X1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dlzka personal_valid 1311\n",
      "Pocet unique pacientov 1311\n",
      "Rozdiel medzi velkostou df a poctu pacientov 0\n",
      "\n",
      "Dlzka other_valid 1361\n",
      "Pocet unique pacientov 1311\n",
      "Rozdiel medzi velkostou df a poctu pacientov 50\n",
      "\n",
      "Dlzka noveho dataframu 1311\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"./data/personal_valid.csv\", index_col=0)\n",
    "df2 = pd.read_csv(\"./data/other_valid.csv\", index_col=0)\n",
    "\n",
    "print(\"Dlzka personal_valid\", df1.shape[0])\n",
    "print(\"Pocet unique pacientov\", df1[\"name\"].nunique())\n",
    "print(\"Rozdiel medzi velkostou df a poctu pacientov\", df1.shape[0] - df1[\"name\"].nunique())\n",
    "print()\n",
    "\n",
    "print(\"Dlzka other_valid\", df2.shape[0])\n",
    "print(\"Pocet unique pacientov\", df2[\"name\"].nunique())\n",
    "print(\"Rozdiel medzi velkostou df a poctu pacientov\", df2.shape[0] - df2[\"name\"].nunique())\n",
    "print()\n",
    "\n",
    "X2,y2 = prep_pip.one_proper_df(df1, df2)\n",
    "print(\"Dlzka noveho dataframu\", X2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1[\"class\"] = y1\n",
    "X2[\"class\"] = y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5244, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([X1,X2])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je potrebne vymazat z datasetu vsetky data, kde target attribute - class je NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5227, 25)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reset_index(drop=True)\n",
    "indices = data.loc[data[\"class\"].isnull()].index.values\n",
    "\n",
    "data = data.drop(index=indices)\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toto je tam len kvoli tomu, aby sme vobec vedeli deklarovat dany pipeline - Teda je potrebne tam dat nejaky krok, ktory hned vymazeme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu sa pridaju kroky z preprocessingu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_steps = prep_pip.get_preprocessing_steps()\n",
    "\n",
    "pip = imblearn.pipeline.Pipeline(steps=[\n",
    "    step for step in prep_steps\n",
    "])\n",
    "    \n",
    "from sklearn import tree\n",
    "pip.steps.append(\n",
    "    (\"classifier\", tree.DecisionTreeClassifier())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu sa specialne volaju parametre, kedze sa nachadzaju v pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"classifier__criterion\" : [\"gini\", \"entropy\"],\n",
    "    \"classifier__max_depth\" :  [3,5,10]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ked sa pouzije n_jobs=-1, co by malo byt tolko procesov paralelne ako pocet threadov, tak to dava NaN vysledky :(\n",
    "\n",
    "Takze budeme musiet to mat pomale..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = model_selection.GridSearchCV(pip, param_grid, scoring=\"f1_weighted\", cv=10, verbose=1, refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('feature_removal',\n",
       "                                        FunctionTransformer(func=<function remove_useless_features at 0x0000022056A59160>)),\n",
       "                                       ('add_oxygen_attr',\n",
       "                                        FunctionTransformer(func=<function add_oxygen_features at 0x0000022056A591F0>)),\n",
       "                                       ('mean_glucose_to_num',\n",
       "                                        FunctionTransformer(func=<function repair_mean_glucose at 0x0000022056A594C0>)),\n",
       "                                       ('string_...\n",
       "                                                                                 'occupation_1',\n",
       "                                                                                 'occupation_2',\n",
       "                                                                                 'occupation_3',\n",
       "                                                                                 'occupation_4',\n",
       "                                                                                 'occupation_5',\n",
       "                                                                                 'occupation_6',\n",
       "                                                                                 'occupation_7',\n",
       "                                                                                 'occupation_8',\n",
       "                                                                                 'workclass_0',\n",
       "                                                                                 'workclass_1', ...],\n",
       "                                                              keep_original_cols=False)),\n",
       "                                       ('classifier',\n",
       "                                        DecisionTreeClassifier())]),\n",
       "             param_grid={'classifier__criterion': ['gini', 'entropy'],\n",
       "                         'classifier__max_depth': [3, 5, 10]},\n",
       "             refit=False, scoring='f1_weighted', verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns=[\"class\"])\n",
    "y = data[\"class\"]\n",
    "\n",
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu su vysledky..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([5.61593139, 6.40554435, 6.89682615, 6.88562021, 6.79604747,\n",
       "        6.56106057]),\n",
       " 'std_fit_time': array([0.71833811, 0.95855436, 0.43341125, 0.14908303, 0.16527628,\n",
       "        0.43965328]),\n",
       " 'mean_score_time': array([0.7026196 , 0.76721764, 0.81051357, 0.78968451, 0.80104363,\n",
       "        0.78645825]),\n",
       " 'std_score_time': array([0.06523823, 0.14797068, 0.05836718, 0.07168917, 0.08448849,\n",
       "        0.11973336]),\n",
       " 'param_classifier__criterion': masked_array(data=['gini', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy'],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__max_depth': masked_array(data=[3, 5, 10, 3, 5, 10],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__criterion': 'gini', 'classifier__max_depth': 3},\n",
       "  {'classifier__criterion': 'gini', 'classifier__max_depth': 5},\n",
       "  {'classifier__criterion': 'gini', 'classifier__max_depth': 10},\n",
       "  {'classifier__criterion': 'entropy', 'classifier__max_depth': 3},\n",
       "  {'classifier__criterion': 'entropy', 'classifier__max_depth': 5},\n",
       "  {'classifier__criterion': 'entropy', 'classifier__max_depth': 10}],\n",
       " 'split0_test_score': array([0.876465  , 0.876465  , 0.87471563, 0.876465  , 0.876465  ,\n",
       "        0.87664966]),\n",
       " 'split1_test_score': array([0.89677402, 0.89677402, 0.89147895, 0.89677402, 0.89677402,\n",
       "        0.89339282]),\n",
       " 'split2_test_score': array([0.88795578, 0.88795578, 0.88268029, 0.88971671, 0.88971671,\n",
       "        0.88986719]),\n",
       " 'split3_test_score': array([0.90338373, 0.89754314, 0.89999931, 0.90338373, 0.90532177,\n",
       "        0.89381744]),\n",
       " 'split4_test_score': array([0.9148409 , 0.91304239, 0.91304239, 0.9148409 , 0.91285332,\n",
       "        0.91322651]),\n",
       " 'split5_test_score': array([0.88906424, 0.89099782, 0.89099782, 0.88906424, 0.88906424,\n",
       "        0.88747387]),\n",
       " 'split6_test_score': array([0.89735895, 0.8994945 , 0.89577207, 0.89735895, 0.89735895,\n",
       "        0.89754314]),\n",
       " 'split7_test_score': array([0.88871586, 0.88695251, 0.88695251, 0.88871586, 0.88871586,\n",
       "        0.88536963]),\n",
       " 'split8_test_score': array([0.87929566, 0.87943682, 0.8776798 , 0.87929566, 0.87929566,\n",
       "        0.87227425]),\n",
       " 'split9_test_score': array([0.89308457, 0.89500337, 0.89147168, 0.89308457, 0.89323684,\n",
       "        0.89323684]),\n",
       " 'mean_test_score': array([0.89269387, 0.89236653, 0.89047904, 0.89286996, 0.89288024,\n",
       "        0.89028514]),\n",
       " 'std_test_score': array([0.01066613, 0.01001075, 0.01056207, 0.01060079, 0.01041622,\n",
       "        0.01073495]),\n",
       " 'rank_test_score': array([3, 4, 5, 2, 1, 6])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8928802369308197"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__criterion': 'entropy', 'classifier__max_depth': 5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
